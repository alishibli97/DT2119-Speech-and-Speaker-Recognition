{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as lb\n",
    "import numpy as np\n",
    "from lab3_proto import *\n",
    "from helper_functions import *\n",
    "from lab1_tools import *\n",
    "import os\n",
    "from pysndfile import sndio\n",
    "import math\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "from scipy.signal import lfilter\n",
    "from scipy.fftpack import fft\n",
    "from scipy.signal import hamming\n",
    "from lab1_tools import *\n",
    "from scipy.fftpack.realtransforms import dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path2info(path):\n",
    "    \"\"\"\n",
    "    path2info: parses paths in the TIDIGIT format and extracts information\n",
    "               about the speaker and the utterance\n",
    "\n",
    "    Example:\n",
    "    path2info('tidigits/disc_4.1.1/tidigits/train/man/ae/z9z6531a.wav')\n",
    "    \"\"\"\n",
    "    rest, filename = os.path.split(path)\n",
    "    rest, speakerID = os.path.split(rest)\n",
    "    rest, gender = os.path.split(rest)\n",
    "    digits = filename[:-5]\n",
    "    repetition = filename[-5]\n",
    "    return gender, speakerID, digits, repetition\n",
    "\n",
    "def loadAudio(filename):\n",
    "    \"\"\"\n",
    "    loadAudio: loads audio data from file using pysndfile\n",
    "\n",
    "    Note that, by default pysndfile converts the samples into floating point\n",
    "    numbers and rescales them in the range [-1, 1]. This is avoided by specifying\n",
    "    the option dtype=np.int16 which keeps both the original data type and range\n",
    "    of values.\n",
    "    \"\"\"\n",
    "    sndobj = sndio.read(filename, dtype=np.int16)\n",
    "    samplingrate = sndobj[1]\n",
    "    samples = np.array(sndobj[0])\n",
    "    return samples, samplingrate\n",
    "\n",
    "def frames2trans(sequence, outfilename=None, timestep=0.01):\n",
    "    \"\"\"\n",
    "    Outputs a standard transcription given a frame-by-frame\n",
    "    list of strings.\n",
    "\n",
    "    Example (using functions from Lab 1 and Lab 2):\n",
    "    phones = ['sil', 'sil', 'sil', 'ow', 'ow', 'ow', 'ow', 'ow', 'sil', 'sil']\n",
    "    trans = frames2trans(phones, 'oa.lab')\n",
    "\n",
    "    Then you can use, for example wavesurfer to open the wav file and the transcription\n",
    "    \"\"\"\n",
    "    sym = sequence[0]\n",
    "    start = 0\n",
    "    end = 0\n",
    "    trans = ''\n",
    "    for t in range(len(sequence)):\n",
    "        if sequence[t] != sym:\n",
    "            trans = trans + str(start) + ' ' + str(end) + ' ' + sym + '\\n'\n",
    "            sym = sequence[t]\n",
    "            start = end\n",
    "        end = end + timestep\n",
    "    trans = trans + str(start) + ' ' + str(end) + ' ' + sym + '\\n'\n",
    "    if outfilename != None:\n",
    "        with open(outfilename, 'w') as f:\n",
    "            f.write(trans)\n",
    "    return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function given by the exercise ----------------------------------\n",
    "\n",
    "def lifter(mfcc, lifter=22):\n",
    "    \"\"\"\n",
    "    Applies liftering to improve the relative range of MFCC coefficients.\n",
    "       mfcc: NxM matrix where N is the number of frames and M the number of MFCC coefficients\n",
    "       lifter: lifering coefficient\n",
    "    Returns:\n",
    "       NxM array with lifeterd coefficients\n",
    "    \"\"\"\n",
    "    nframes, nceps = mfcc.shape\n",
    "    cepwin = 1.0 + lifter/2.0 * np.sin(np.pi * np.arange(nceps) / lifter)\n",
    "    l = np.multiply(mfcc, np.tile(cepwin, nframes).reshape((nframes,nceps)))\n",
    "    return l\n",
    "\n",
    "def hz2mel(f):\n",
    "    \"\"\"Convert an array of frequency in Hz into mel.\"\"\"\n",
    "    return 1127.01048 * np.log(f/700 +1)\n",
    "\n",
    "def trfbank(fs, nfft, lowfreq=133.33, linsc=200/3., logsc=1.0711703, nlinfilt=13, nlogfilt=27, equalareas=False):\n",
    "    \"\"\"Compute triangular filterbank for MFCC computation.\n",
    "    Inputs:\n",
    "    fs:         sampling frequency (rate)\n",
    "    nfft:       length of the fft\n",
    "    lowfreq:    frequency of the lowest filter\n",
    "    linsc:      scale for the linear filters\n",
    "    logsc:      scale for the logaritmic filters\n",
    "    nlinfilt:   number of linear filters\n",
    "    nlogfilt:   number of log filters\n",
    "    Outputs:\n",
    "    res:  array with shape [N, nfft], with filter amplitudes for each column.\n",
    "            (N=nlinfilt+nlogfilt)\n",
    "    From scikits.talkbox\"\"\"\n",
    "    # Total number of filters\n",
    "    nfilt = nlinfilt + nlogfilt\n",
    "\n",
    "    #------------------------\n",
    "    # Compute the filter bank\n",
    "    #------------------------\n",
    "    # Compute start/middle/end points of the triangular filters in spectral\n",
    "    # domain\n",
    "    freqs = np.zeros(nfilt+2)\n",
    "    freqs[:nlinfilt] = lowfreq + np.arange(nlinfilt) * linsc\n",
    "    freqs[nlinfilt:] = freqs[nlinfilt-1] * logsc ** np.arange(1, nlogfilt + 3)\n",
    "    if equalareas:\n",
    "        heights = np.ones(nfilt)\n",
    "    else:\n",
    "        heights = 2./(freqs[2:] - freqs[0:-2])\n",
    "\n",
    "    # Compute filterbank coeff (in fft domain, in bins)\n",
    "    fbank = np.zeros((nfilt, nfft))\n",
    "    # FFT bins (in Hz)\n",
    "    nfreqs = np.arange(nfft) / (1. * nfft) * fs\n",
    "    for i in range(nfilt):\n",
    "        low = freqs[i]\n",
    "        cen = freqs[i+1]\n",
    "        hi = freqs[i+2]\n",
    "\n",
    "        lid = np.arange(np.floor(low * nfft / fs) + 1,\n",
    "                        np.floor(cen * nfft / fs) + 1, dtype=np.int)\n",
    "        lslope = heights[i] / (cen - low)\n",
    "        rid = np.arange(np.floor(cen * nfft / fs) + 1,\n",
    "                        np.floor(hi * nfft / fs) + 1, dtype=np.int)\n",
    "        rslope = heights[i] / (hi - cen)\n",
    "        fbank[i][lid] = lslope * (nfreqs[lid] - low)\n",
    "        fbank[i][rid] = rslope * (hi - nfreqs[rid])\n",
    "\n",
    "    return fbank\n",
    "\n",
    "\n",
    "def mspec(samples, winlen = 400, winshift = 200, preempcoeff=0.97, nfft=512, samplingrate=20000):\n",
    "    \"\"\"Computes Mel Filterbank features.\n",
    "    Args:\n",
    "        samples: array of speech samples with shape (N,)\n",
    "        winlen: lenght of the analysis window\n",
    "        winshift: number of samples to shift the analysis window at every time step\n",
    "        preempcoeff: pre-emphasis coefficient\n",
    "        nfft: length of the Fast Fourier Transform (power of 2, >= winlen)\n",
    "        samplingrate: sampling rate of the original signal\n",
    "\n",
    "    Returns:\n",
    "        N x nfilters array with mel filterbank features (see trfbank for nfilters)\n",
    "    \"\"\"\n",
    "    frames = enframe(samples, winlen, winshift)\n",
    "    preemph = preemp(frames, preempcoeff)\n",
    "    windowed = windowing(preemph)\n",
    "    spec = powerSpectrum(windowed, nfft)\n",
    "    return logMelSpectrum(spec, samplingrate)\n",
    "\n",
    "def mfcc(samples, winlen = 400, winshift = 200, preempcoeff=0.97, nfft=512, nceps=13, samplingrate=20000, liftercoeff=22):\n",
    "    \"\"\"Computes Mel Frequency Cepstrum Coefficients.\n",
    "\n",
    "    Args:\n",
    "        samples: array of speech samples with shape (N,)\n",
    "        winlen: lenght of the analysis window\n",
    "        winshift: number of samples to shift the analysis window at every time step\n",
    "        preempcoeff: pre-emphasis coefficient\n",
    "        nfft: length of the Fast Fourier Transform (power of 2, >= winlen)\n",
    "        nceps: number of cepstrum coefficients to compute\n",
    "        samplingrate: sampling rate of the original signal\n",
    "        liftercoeff: liftering coefficient used to equalise scale of MFCCs\n",
    "\n",
    "    Returns:\n",
    "        N x nceps array with lifetered MFCC coefficients\n",
    "    \"\"\"\n",
    "    mspecs = mspec(samples, winlen, winshift, preempcoeff, nfft, samplingrate)\n",
    "    ceps = cepstrum(mspecs, nceps)\n",
    "    return lifter(ceps, liftercoeff)\n",
    "\n",
    "# Functions to be implemented ----------------------------------\n",
    "\n",
    "def enframe(samples, winlen, winshift):\n",
    "    \"\"\"\n",
    "    Slices the input samples into overlapping windows.\n",
    "\n",
    "    Args:\n",
    "        winlen: window length in samples.\n",
    "        winshift: shift of consecutive windows in samples\n",
    "    Returns:\n",
    "        numpy array [N x winlen], where N is the number of windows that fit\n",
    "        in the input signal\n",
    "    \"\"\"\n",
    "\n",
    "    # check if i+winlen > len(samples):\n",
    "\n",
    "    result = []\n",
    "    for i in range(0,len(samples),winshift):\n",
    "        if(i+winlen > len(samples)): break\n",
    "        result.append(samples[i:i+winlen])\n",
    "    return np.array(result)\n",
    "    # return np.array([samples[i:i+winlen] for i in range(0,len(samples),winshift)])\n",
    "    \n",
    "def preemp(input, p=0.97):\n",
    "    \"\"\"\n",
    "    Pre-emphasis filter.\n",
    "\n",
    "    Args:\n",
    "        input: array of speech frames [N x M] where N is the number of frames and\n",
    "               M the samples per frame\n",
    "        p: preemhasis factor (defaults to the value specified in the exercise)\n",
    "\n",
    "    Output:\n",
    "        output: array of pre-emphasised speech samples\n",
    "    Note (you can use the function lfilter from scipy.signal)\n",
    "    \"\"\"\n",
    "    return lfilter([1, -p], [1], input)\n",
    "\n",
    "def windowing(input):\n",
    "    \"\"\"\n",
    "    Applies hamming window to the input frames.\n",
    "\n",
    "    Args:\n",
    "        input: array of speech samples [N x M] where N is the number of frames and\n",
    "               M the samples per frame\n",
    "    Output:\n",
    "        array of windoed speech samples [N x M]\n",
    "    Note (you can use the function hamming from scipy.signal, include the sym=0 option\n",
    "    if you want to get the same results as in the example)\n",
    "    \"\"\"\n",
    "    return input * hamming(input.shape[1], sym=0)\n",
    "\n",
    "def powerSpectrum(input, nfft):\n",
    "    \"\"\"\n",
    "    Calculates the power spectrum of the input signal, that is the square of the modulus of the FFT\n",
    "\n",
    "    Args:\n",
    "        input: array of speech samples [N x M] where N is the number of frames and\n",
    "               M the samples per frame\n",
    "        nfft: length of the FFT\n",
    "    Output:\n",
    "        array of power spectra [N x nfft]\n",
    "    Note: you can use the function fft from scipy.fftpack\n",
    "    \"\"\"\n",
    "    freq = fft(input, nfft)\n",
    "    return freq.real**2 + freq.imag**2\n",
    "\n",
    "def logMelSpectrum(input, samplingrate):\n",
    "    \"\"\"\n",
    "    Calculates the log output of a Mel filterbank when the input is the power spectrum\n",
    "\n",
    "    Args:\n",
    "        input: array of power spectrum coefficients [N x nfft] where N is the number of frames and\n",
    "               nfft the length of each spectrum\n",
    "        samplingrate: sampling rate of the original signal (used to calculate the filterbank shapes)\n",
    "    Output:\n",
    "        array of Mel filterbank log outputs [N x nmelfilters] where nmelfilters is the number\n",
    "        of filters in the filterbank\n",
    "    Note: use the trfbank function provided in lab1_tools.py to calculate the filterbank shapes and\n",
    "          nmelfilters\n",
    "    \"\"\"\n",
    "    nfft = input.shape[1]\n",
    "    tr_filter = trfbank(samplingrate, nfft)\n",
    "    return np.log(np.dot(input, tr_filter.transpose()))\n",
    "\n",
    "def cepstrum(input, nceps):\n",
    "    \"\"\"\n",
    "    Calulates Cepstral coefficients from mel spectrum applying Discrete Cosine Transform\n",
    "\n",
    "    Args:\n",
    "        input: array of log outputs of Mel scale filterbank [N x nmelfilters] where N is the\n",
    "               number of frames and nmelfilters the length of the filterbank\n",
    "        nceps: number of output cepstral coefficients\n",
    "    Output:\n",
    "        array of Cepstral coefficients [N x nceps]\n",
    "    Note: you can use the function dct from scipy.fftpack.realtransforms\n",
    "    \"\"\"\n",
    "    return dct(input)[:,0:nceps]\n",
    "\n",
    "def dtw(x, y, dist):\n",
    "    \"\"\"Dynamic Time Warping.\n",
    "\n",
    "    Args:\n",
    "        x, y: arrays of size NxD and MxD respectively, where D is the dimensionality\n",
    "              and N, M are the respective lenghts of the sequences\n",
    "        dist: distance function (can be used in the code as dist(x[i], y[j]))\n",
    "\n",
    "    Outputs:\n",
    "        d: global distance between the sequences (scalar) normalized to len(x)+len(y)\n",
    "        LD: local distance between frames from x and y (NxM matrix)\n",
    "        AD: accumulated distance between frames of x and y (NxM matrix)\n",
    "        path: best path thtough AD\n",
    "\n",
    "    Note that you only need to define the first output for this exercise.\n",
    "    \"\"\"\n",
    "\n",
    "    AD = np.zeros(dist.shape)\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(y)):\n",
    "            AD[i,j] = dist[i,j] + min(AD[i - 1, j], AD[i, j - 1], AD[i - 1, j - 1])\n",
    "    \n",
    "    d = AD[-1, -1]/(x.shape[0] + y.shape[0])\n",
    "\n",
    "    return d, dist, AD\n",
    "\n",
    "def viterbi(log_emlik, log_startprob, log_transmat, forceFinalState=True):\n",
    "    \"\"\"Viterbi path.\n",
    "    Args:\n",
    "        log_emlik: NxM array of emission log likelihoods, N frames, M states\n",
    "        log_startprob: log probability to start in state i\n",
    "        log_transmat: transition log probability from state i to j\n",
    "        forceFinalState: if True, start backtracking from the final state in\n",
    "                  the model, instead of the best state at the last time step\n",
    "    Output:\n",
    "        viterbi_loglik: log likelihood of the best path\n",
    "        viterbi_path: best path\n",
    "    \"\"\"\n",
    "\n",
    "    B = np.zeros(log_emlik.shape, dtype = int)\n",
    "    V = np.zeros(log_emlik.shape)\n",
    "    V[0] = log_startprob.flatten() + log_emlik[0]\n",
    "\n",
    "    for n in range(1, log_emlik.shape[0]):\n",
    "        for j in range(log_emlik.shape[1]):\n",
    "            V[n][j] = np.max(V[n - 1,:] + log_transmat[:,j]) + log_emlik[n, j]\n",
    "            B[n][j] = np.argmax(V[n - 1,:] + log_transmat[:,j])\n",
    "\n",
    "    lastIdx = np.argmax(V[log_emlik.shape[0] - 1])\n",
    "\n",
    "    viterbi_path = [lastIdx]\n",
    "    for i in reversed(range(1, B.shape[0])):\n",
    "        viterbi_path.append(B[i, viterbi_path[-1]])\n",
    "    viterbi_path.reverse()\n",
    "    viterbi_path = np.array(viterbi_path)\n",
    "\n",
    "    return np.max(V[ log_emlik.shape[0] - 1]), viterbi_path\n",
    "\n",
    "def log_multivariate_normal_density_diag(X, means, covars):\n",
    "    \"\"\"Compute Gaussian log-density at X for a diagonal model\n",
    "\n",
    "    Args:\n",
    "        X: array like, shape (n_observations, n_features)\n",
    "        means: array like, shape (n_components, n_features)\n",
    "        covars: array like, shape (n_components, n_features)\n",
    "\n",
    "    Output:\n",
    "        lpr: array like, shape (n_observations, n_components)\n",
    "    From scikit-learn/sklearn/mixture/gmm.py\n",
    "    \"\"\"\n",
    "    n_samples, n_dim = X.shape\n",
    "    lpr = -0.5 * (n_dim * np.log(2 * np.pi) + np.sum(np.log(covars), 1)\n",
    "                  + np.sum((means ** 2) / covars, 1)\n",
    "                  - 2 * np.dot(X, (means / covars).T)\n",
    "                  + np.dot(X ** 2, (1.0 / covars).T))\n",
    "    return lpr\n",
    "\n",
    "def concatTwoHMMs(hmm1, hmm2):\n",
    "    \"\"\" Concatenates 2 HMM models\n",
    "    Args:\n",
    "       hmm1, hmm2: two dictionaries with the following keys:\n",
    "           name: phonetic or word symbol corresponding to the model\n",
    "           startprob: M+1 array with priori probability of state\n",
    "           transmat: (M+1)x(M+1) transition matrix\n",
    "           means: MxD array of mean vectors\n",
    "           covars: MxD array of variances\n",
    "    D is the dimension of the feature vectors\n",
    "    M is the number of emitting states in each HMM model (could be different for each)\n",
    "    Output\n",
    "       dictionary with the same keys as the input but concatenated models:\n",
    "          startprob: K+1 array with priori probability of state\n",
    "          transmat: (K+1)x(K+1) transition matrix\n",
    "             means: KxD array of mean vectors\n",
    "            covars: KxD array of variances\n",
    "    K is the sum of the number of emitting states from the input models\n",
    "   \n",
    "    Example:\n",
    "       twoHMMs = concatHMMs(phoneHMMs['sil'], phoneHMMs['ow'])\n",
    "    See also: the concatenating_hmms.pdf document in the lab package\n",
    "    \"\"\"\n",
    "    \n",
    "    concatedHMM = {}\n",
    "    #M is the number of emitting states in each HMM model (could be different for each)\n",
    "    #K is the sum of the number of emitting states from the input models\n",
    "    \n",
    "    M1 = hmm1['means'].shape[0]\n",
    "    M2 = hmm2['means'].shape[0]\n",
    "    K = M1 + M2\n",
    "    \n",
    "    concatedHMM['name'] = hmm1['name'] + hmm2['name']\n",
    "    concatedHMM['startprob'] = np.zeros((K + 1, 1))\n",
    "    concatedHMM['transmat'] = np.zeros((K + 1, K + 1))\n",
    "    concatedHMM['means'] = np.vstack((hmm1['means'],hmm2['means']))\n",
    "    concatedHMM['covars'] = np.vstack((hmm1['covars'],hmm2['covars']))\n",
    "        \n",
    "    \n",
    "    start1 = hmm1['startprob'].reshape(-1,1)\n",
    "    start2 = hmm2['startprob'].reshape(-1,1)\n",
    "    \n",
    "    concatedHMM['startprob'][:hmm1['startprob'].shape[0]-1,:] = start1[:-1,:]\n",
    "    concatedHMM['startprob'][hmm1['startprob'].shape[0]-1:,:] = np.dot(start1[-1,0],start2)\n",
    "    trans = concatedHMM['transmat']\n",
    "    trans1 = hmm1['transmat']\n",
    "    trans2 = hmm2['transmat']\n",
    "\n",
    "    trans[:trans1.shape[0]-1,:trans1.shape[1]-1] = trans1[:-1,:-1]\n",
    "    temp = trans1[:-1,-1].reshape(-1,1)\n",
    "    trans[:trans1.shape[0]-1,trans1.shape[1]-1:] = \\\n",
    "                            np.dot(temp,start2.T)\n",
    "    trans[trans1.shape[0]-1:,trans1.shape[1]-1:] = trans2\n",
    "    concatedHMM['transmat'] = trans    \n",
    "    \n",
    "    return concatedHMM\n",
    "\n",
    "\n",
    "# this is already implemented, but based on concat2HMMs() above\n",
    "def concatHMMs(hmmmodels, namelist):\n",
    "    \"\"\" Concatenates HMM models in a left to right manner\n",
    "    Args:\n",
    "       hmmmodels: dictionary of models indexed by model name. \n",
    "       hmmmodels[name] is a dictionaries with the following keys:\n",
    "           name: phonetic or word symbol corresponding to the model\n",
    "           startprob: M+1 array with priori probability of state\n",
    "           transmat: (M+1)x(M+1) transition matrix\n",
    "           means: MxD array of mean vectors\n",
    "           covars: MxD array of variances\n",
    "       namelist: list of model names that we want to concatenate\n",
    "    D is the dimension of the feature vectors\n",
    "    M is the number of emitting states in each HMM model (could be\n",
    "      different in each model)\n",
    "    Output\n",
    "       combinedhmm: dictionary with the same keys as the input but\n",
    "                    combined models:\n",
    "         startprob: K+1 array with priori probability of state\n",
    "          transmat: (K+1)x(K+1) transition matrix\n",
    "             means: KxD array of mean vectors\n",
    "            covars: KxD array of variances\n",
    "    K is the sum of the number of emitting states from the input models\n",
    "    Example:\n",
    "       wordHMMs['o'] = concatHMMs(phoneHMMs, ['sil', 'ow', 'sil'])\n",
    "    \"\"\"\n",
    "    concat = hmmmodels[namelist[0]]\n",
    "    for idx in range(1,len(namelist)):\n",
    "        concat = concatTwoHMMs(concat, hmmmodels[namelist[idx]])\n",
    "    return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/Users/nandakishorprabhu/Documents/Studies/DT2119/Code'\n",
    "phoneHMMs = np.load('lab2_models_all.npz',allow_pickle=True)['phoneHMMs'].item()\n",
    "phones = sorted(phoneHMMs.keys())\n",
    "nstates = {phone: phoneHMMs[phone]['means'].shape[0] for phone in phones}\n",
    "# stateList = [ph + '_' + str(id) for ph in phones for id in range(nstates[ph])]\n",
    "# f = open(\"stateList.txt\",\"w\")\n",
    "# for state in stateList:\n",
    "#     f.write(f\"{state}\\n\")\n",
    "stateList = open(\"stateList.txt\", \"r\").readlines()\n",
    "stateList = [state.strip() for state in stateList]\n",
    "\n",
    "example_data = np.load(\"lab3_example.npz\", allow_pickle=True)['example']\n",
    "example_data = dict(enumerate(example_data.flatten(), 1))[1]\n",
    "filename = example_data['filename']\n",
    "wordTrans = list(path2info(filename)[2])\n",
    "# print(wordTrans)\n",
    "\n",
    "prondict = {}\n",
    "prondict['o'] = ['ow']\n",
    "prondict['z'] = ['z', 'iy', 'r', 'ow']\n",
    "prondict['1'] = ['w', 'ah', 'n']\n",
    "prondict['2'] = ['t', 'uw']\n",
    "prondict['3'] = ['th', 'r', 'iy']\n",
    "prondict['4'] = ['f', 'ao', 'r']\n",
    "prondict['5'] = ['f', 'ay', 'v']\n",
    "prondict['6'] = ['s', 'ih', 'k', 's']\n",
    "prondict['7'] = ['s', 'eh', 'v', 'ah', 'n']\n",
    "prondict['8'] = ['ey', 't']\n",
    "prondict['9'] = ['n', 'ay', 'n']\n",
    "\n",
    "phoneTrans = words2phones(wordTrans, prondict)\n",
    "# print(phoneTrans)\n",
    "\n",
    "utteranceHMM = concatHMMs(phoneHMMs, phoneTrans)\n",
    "# print(utteranceHMM)\n",
    "\n",
    "# stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans for stateid in range(nstates[phone])]\n",
    "# f = open(\"stateTrans.txt\",\"w\")\n",
    "# for state in stateTrans:\n",
    "#     f.write(f\"{state}\\n\")\n",
    "stateTrans = open(\"stateTrans.txt\", \"r\").readlines()\n",
    "stateTrans = [state.strip() for state in stateTrans]\n",
    "# print(stateTrans[10])\n",
    "\n",
    "# X = example_data['lmfcc']\n",
    "# means = utteranceHMM['means']\n",
    "# covars = utteranceHMM['covars']\n",
    "# log_likelihood = log_multivariate_normal_density_diag(X,means,covars)\n",
    "\n",
    "# log_startprob = np.log(utteranceHMM['startprob'][:-1])\n",
    "# log_transmat = np.log(utteranceHMM['transmat'][:-1,:-1])\n",
    "\n",
    "# prob,viterbiStateTrans = viterbi(log_likelihood,log_startprob,log_transmat)\n",
    "# # print(viterbiStateTrans)\n",
    "\n",
    "# vpath = [stateTrans[i] for i in viterbiStateTrans]\n",
    "# print(vpath)\n",
    "# viterbiStateTrans = forcedAlignment(example_data['lmfcc'], utteranceHMM, phoneTrans)\n",
    "# vpath = [stateTrans[i] for i in viterbiStateTrans]\n",
    "# print(vpath)\n",
    "# frames = frames2trans(vpath, outfilename='z43a.lab')\n",
    "# print(frames)\n",
    "\n",
    "filenames = ['/Users/nandakishorprabhu/Documents/Studies/DT2119/Code/traindata.npz']\n",
    "sets = ['/Users/nandakishorprabhu/Documents/Studies/DT2119/Code/tidigits/disc_4.1.1/tidigits/train']\n",
    "for idx, file_name in enumerate(filenames):\n",
    "    i = 0\n",
    "    if not os.path.isfile(file_name):\n",
    "        data = []\n",
    "        for root, dirs, files in os.walk(sets[idx]):\n",
    "            for file in files:\n",
    "                if file.endswith('.wav'):\n",
    "                    filename = os.path.join(root, file)\n",
    "                    samples, samplingrate = loadAudio(filename)\n",
    "                    lmfcc = mfcc(samples)\n",
    "                    mspecs = mspec(samples)\n",
    "                    wordTrans = list(path2info(filename)[2])\n",
    "                    phoneTrans = words2phones(wordTrans, prondict)\n",
    "                    targets = forcedAlignment(lmfcc, utteranceHMM, phoneTrans)\n",
    "                    data.append({'filename': filename, 'lmfcc': lmfcc, 'mspec': mspecs, 'targets': targets})\n",
    "#             if file_name == 'traindata.npz':\n",
    "#                 np.savez('/Users/nandakishorprabhu/Documents/Studies/DT2119/Code/traindata.npz', traindata=data)\n",
    "#             elif file_name == 'testdata.npz':\n",
    "#                 np.savez(PATH + file_name, testdata=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(datapath, saveName):\n",
    "    traindata = []\n",
    "#     stateList = list()\n",
    "#     with open(stateListPath) as f:\n",
    "#         for line in f:\n",
    "#             stateList.append(line.strip('\\n'))\n",
    "\n",
    "    totalfiles = 0\n",
    "    for root, dirs, files in os.walk(datapath):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                totalfiles += 1\n",
    "\n",
    "    for root, dirs, files in os.walk(datapath):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                filename = os.path.join(root, file)\n",
    "                samples, samplingrate = loadAudio(filename)\n",
    "                lmfcc = mfcc(samples)\n",
    "                mspecs = mspec(samples)\n",
    "                wordTrans = list(path2info(filename)[2])\n",
    "                phoneTrans = words2phones(wordTrans, prondict, addShortPause=False)\n",
    "                targets = forcedAlignment(lmfcc, utteranceHMM, phoneTrans)\n",
    "\n",
    "                traindata.append({'filename': filename,\n",
    "                                 'lmfcc': lmfcc,\n",
    "                                 'mspec': mspec,\n",
    "                                 'targets':targets})\n",
    "    return traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = prepare_features('tidigits/disc_4.1.1/tidigits/train', 'traindata.npz')\n",
    "np.savez('/Users/nandakishorprabhu/Documents/Studies/DT2119/Code/DT2119-Speech-and-Speaker-Recognition/lab3/traindata.npz', traindata = traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'traindata': array([], dtype=float64)}\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-04223aa28523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm_valid_data\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw_valid_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Data : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'traindata'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation Data :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'traindata'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "traindata = np.load('traindata.npz', allow_pickle = True)\n",
    "traindata = dict(zip((\"{}\".format(k) for k in traindata), (traindata[k] for k in traindata)))\n",
    "print(traindata)\n",
    "male_speakers = np.unique([traindata['traindata'][i][\"filename\"].split('/')[6] \n",
    "#                       for i in range(len(traindata['traindata'])) \n",
    "                      if traindata['traindata'][i][\"filename\"].split('/')[4] == 'man'])\n",
    "female_speakers = np.unique([traindata['traindata'][i][\"filename\"].split('/')[6] \n",
    "                      for i in range(len(traindata['traindata'])) \n",
    "                      if traindata['traindata'][i][\"filename\"].split('/')[4] == 'woman'])\n",
    "\n",
    "\n",
    "m_train_speakers = male_speakers[0:math.floor(len(male_speakers)*0.9)]\n",
    "m_valid_speakers = male_speakers[math.floor(len(male_speakers)*0.9):]\n",
    "\n",
    "# print(len(m_train_speakers))\n",
    "# print(m_valid_speakers)\n",
    "\n",
    "m_train_data =  [traindata['traindata'][i] for i in range(len(traindata['traindata']))\n",
    "                  if traindata['traindata'][i][\"filename\"].split('/')[6] in m_train_speakers]\n",
    "\n",
    "m_valid_data =  [traindata['traindata'][i] for i in range(len(traindata['traindata'])) \n",
    "                  if traindata['traindata'][i][\"filename\"].split('/')[6] in m_valid_speakers]\n",
    "\n",
    "w_train_speakers = female_speakers[0:math.floor(len(female_speakers)*0.9)]\n",
    "w_valid_speakers = female_speakers[math.floor(len(female_speakers)*0.9):]\n",
    "\n",
    "w_train_data =  [traindata['traindata'][i] for i in range(len(traindata['traindata'])) \n",
    "                  if traindata['traindata'][i][\"filename\"].split('/')[6] in w_train_speakers]\n",
    "\n",
    "w_valid_data =  [traindata['traindata'][i] for i in range(len(traindata['traindata'])) \n",
    "                  if traindata['traindata'][i][\"filename\"].split('/')[6] in w_valid_speakers]\n",
    "\n",
    "training_data = m_train_data + w_train_data\n",
    "validation_data = m_valid_data + w_valid_data\n",
    "\n",
    "print(\"Training Data : \", len(training_data)/len(traindata['traindata'])*100)\n",
    "print(\"Validation Data :\", len(validation_data)/len(traindata['traindata'])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamize_features(data, feature_type):\n",
    "    for sample in (data):\n",
    "        print(sample)\n",
    "        dynamic_features = []\n",
    "        max_idx = len(sample[feature_type]) - 1\n",
    "        for idx, feature in enumerate(sample[feature_type]):\n",
    "            dynamic_feature = np.zeros((7, feature.shape[0]))\n",
    "\n",
    "            dynamic_feature[0] = sample[feature_type][np.abs(idx - 3)]\n",
    "            dynamic_feature[1] = sample[feature_type][np.abs(idx - 2)]\n",
    "            dynamic_feature[2] = sample[feature_type][np.abs(idx - 1)]\n",
    "            dynamic_feature[3] = sample[feature_type][idx]\n",
    "            dynamic_feature[4] = sample[feature_type][max_idx - np.abs(max_idx - (idx + 1))]\n",
    "            dynamic_feature[5] = sample[feature_type][max_idx - np.abs(max_idx - (idx + 2))]\n",
    "            dynamic_feature[6] = sample[feature_type][max_idx - np.abs(max_idx - (idx + 3))]\n",
    "            dynamic_features.append(dynamic_feature)\n",
    "        sample['dynamic_'+feature_type] = np.array(dynamic_features)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = dynamize_features(training_data[0:10], 'lmfcc')\n",
    "training_data = dynamize_features(training_data[0:10], 'mspec')\n",
    "\n",
    "validation_data = dynamize_features(validation_data[0:10], 'mspec')\n",
    "validation_data = dynamize_features(validation_data[0:10], 'lmfcc')\n",
    "print(\"Original Features \", training_data[0][\"lmfcc\"].shape)\n",
    "print(\"Dynamic Features \", training_data[0]['dynamic_lmfcc'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
